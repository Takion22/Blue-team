{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
        "\n",
        "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
      ],
      "metadata": {
        "id": "a8E7De68YVps"
      },
      "id": "a8E7De68YVps"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Détails de l'étudiant\n",
        "### Nom(s)  :RANDRIANANTENAINA\n",
        "### Prénom(s) :Jean Carlos\n",
        "### Classe :IMTICIA 4"
      ],
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "id": "K6EHkj63XsUy"
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## Étape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En Deep Learning, la vérification de l'environnement de développement est une étape fondamentale :\n",
        "\n",
        "- la reproduction du modèle:les versions des librairies (TensorFlow, PyTorch, etc.) et leurs dépendances peuvent influencer le comportement du modèle. En vérifiant la configuration, vous vous assurez que votre modèle se comporte comme prévu et que vos résultats sont reproductibles par d'autres.\n",
        "\n",
        "- La stabilité :  Un environnement de développement stable est essentiel pour éviter les bugs et les erreurs d'exécution. Des incompatibilités entre les librairies peuvent entraîner des problèmes imprévisibles. En vérifiant la configuration, vous minimisez les risques d'instabilité et vous vous assurez que votre code fonctionne correctement.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HqKKXDdRexIA"
      },
      "id": "HqKKXDdRexIA"
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## Étape 2 : Chargement et Prétraitement des Données\n",
        "\n",
        "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La normalisation des pixels et le one-hot encoding sont deux techniques de prétraitement des données qui jouent un rôle crucial dans la stabilité et l'efficacité de l'entraînement des modèles de deep learning. Allons voir ci-dessous ces techniques.\n",
        "\n",
        "- Normalisation des pixels :\n",
        "\n",
        "    Stabilité : Les réseaux de neurones utilisent des fonctions d'activation qui sont sensibles à l'échelle des données d'entrée. Si les valeurs des pixels sont très importantes (par exemple, entre 0 et 255), les gradients calculés pendant l'entraînement peuvent devenir très grands ou très petits, ce qui rend l'optimisation difficile. La normalisation, en ramenant les valeurs des pixels à une échelle commune (par exemple, entre 0 et 1), permet de stabiliser l'entraînement et d'éviter les problèmes de gradients explosifs ou disparaissants.\n",
        "    Efficacité : La normalisation des pixels permet également d'accélérer l'entraînement du modèle. En effet, lorsque les données sont normalisées, le nombre d'itérations nécessaires pour atteindre une performance optimale est reduite.\n",
        "\n",
        "- One-hot encoding des étiquettes :\n",
        "\n",
        "    Stabilité : Le one-hot encoding consiste à transformer les étiquettes  en vecteurs binaires. Cela permet d'éviter que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui pourrait induire des biais dans l'apprentissage. Par exemple, si les étiquettes sont \"chat\", \"chien\" et \"oiseau\", le modèle pourrait interpréter \"chien\" comme étant \"entre\" \"chat\" et \"oiseau\", ce qui est incorrect. Le one-hot encoding permet de représenter chaque classe de manière indépendante, garantissant une meilleure stabilité de l'apprentissage.\n",
        "    Efficacité : Le one-hot encoding permet également d'améliorer l'efficacité de l'entraînement en facilitant le calcul des gradients. En effet, la représentation binaire des étiquettes permet d'utiliser des fonctions d'activation et des fonctions de perte plus adaptées à la classification multiclasse, ce qui accélère la convergence du modèle.\n"
      ],
      "metadata": {
        "id": "K0xMfGyXgWjV"
      },
      "id": "K0xMfGyXgWjV"
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## Étape 3 : Exploration et Visualisation des Données\n",
        "\n",
        "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de données d'entraînement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La performance d'un modèle de classification d'images repose en grande partie sur la qualité et la distribution des données d'entraînement. Deux aspects sont particulièrement importants à considérer :\n",
        "\n",
        "- La distribution inégale des classes : Imaginez que vous entraîniez un modèle à reconnaître des chats et des chiens, mais que votre jeu de données contient 90% d'images de chats et seulement 10% d'images de chiens. Le modèle aura tendance à se spécialiser dans la reconnaissance des chats et sera moins performant sur les chiens. Ce biais vers la classe majoritaire peut affecter la capacité du modèle à généraliser sur de nouvelles données.\n",
        "\n",
        "Solutions :\n",
        "\n",
        "  Rééquilibrage des classes ,plusieurs techniques permettent de corriger ce déséquilibre, comme le sur-échantillonnage de la classe minoritaire (par génération de nouvelles images, par exemple), le sous-échantillonnage de la classe majoritaire, ou encore l'attribution de poids plus importants aux exemples de la classe minoritaire pendant l'entraînement.\n",
        "    \n",
        "- La présence d'images de mauvaise qualité : un obstacle à l'apprentissage\n",
        "\n",
        "Des images floues, bruitées, ou mal cadrées peuvent perturber l'apprentissage du modèle, en l'empêchant d'extraire des caractéristiques pertinentes et en le rendant plus sensible aux variations non significatives.\n",
        "\n",
        "Solutions :\n",
        "\n",
        "  Amélioration des données : Appliquer des techniques de traitement d'images pour réduire le bruit, améliorer la netteté, ou corriger les problèmes de cadrage. Il est également crucial de supprimer les images inutilisables qui pourraient nuire à l'apprentissage.\n",
        "  "
      ],
      "metadata": {
        "id": "jIdmwz0Ygpqb"
      },
      "id": "jIdmwz0Ygpqb"
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## Étape 4 : Construction du Modèle CNN\n",
        "\n",
        "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le modèle CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un réseau de neurones convolutif (CNN) est conçu pour analyser des images et en extraire des informations pertinentes pour la classification. Pour cela, il utilise une combinaison de couches spécifiques : convolution, pooling et dropout.\n",
        "\n",
        " - Couches de convolution : détectent des motifs locaux dans l'image, comme des contours ou des textures.\n",
        "\n",
        "- Couches de pooling : réduisent la dimensionnalité des cartes de caractéristiques, simplifiant l'information et augmentant la robustesse.\n",
        "\n",
        "- Dropout : prévient le surapprentissage en désactivant aléatoirement des neurones pendant l'entraînement.\n"
      ],
      "metadata": {
        "id": "dbDXrWV-hvpv"
      },
      "id": "dbDXrWV-hvpv"
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## Étape 5 : Compilation et Entraînement du Modèle\n",
        "\n",
        "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les hyperparamètres, tels que le taux d'apprentissage et la taille du batch, jouent un rôle crucial dans l'entraînement d'un réseau de neurones. Un choix inadapté peut avoir des conséquences significatives sur la performance et la convergence du modèle.\n",
        "\n",
        "Effets d'un mauvais choix d'hyperparamètres :\n",
        "\n",
        "\n",
        "- Taux d'apprentissage trop élevé : le modèle peut diverger et ne pas converger vers une solution optimale.\n",
        "\n",
        "- Taux d'apprentissage trop faible : l'entraînement sera lent et le modèle peut rester bloqué dans un minimum local.\n",
        "- Taille du batch trop grande : le modèle peut converger vers un minimum local moins performant.\n",
        "- Taille du batch trop petite : l'entraînement sera lent et les mises à jour des poids seront plus bruitées.\n",
        "\n",
        "Importance d'un optimiseur bien configuré :\n",
        "\n",
        "  - L'optimiseur ajuste les poids du modèle pour minimiser la fonction de perte.\n",
        "  - Un bon optimiseur garantit une convergence rapide et une performance optimale.\n",
        "  -  Les hyperparamètres de l'optimiseur doivent être ajustés avec soin pour éviter les problèmes de convergence.\n"
      ],
      "metadata": {
        "id": "0l8ETEHch9Tm"
      },
      "id": "0l8ETEHch9Tm"
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## Étape 6 : Évaluation du Modèle\n",
        "\n",
        "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
        "\n",
        "### Explication Pratique\n",
        "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Précision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lors de l'évaluation d'un modèle sur le jeu de test, on obtient deux indicateurs clés : la perte (loss) et la précision (accuracy). Ces métriques nous renseignent sur la capacité du modèle à généraliser sur des données inédites et à effectuer des prédictions correctes.\n",
        "\n",
        "Que nous indiquent la perte et la précision ?\n",
        "\n",
        " -  La perte (loss) : Elle mesure l'erreur du modèle dans ses prédictions. Une perte faible indique que le modèle est capable de prédire les classes avec une grande précision.\n",
        "\n",
        "- La précision (accuracy) : Elle représente le pourcentage de prédictions correctes effectuées par le modèle sur le jeu de test. Une précision élevée indique que le modèle est capable de classifier correctement la plupart des images.\n",
        "\n",
        "Analyser l'écart entre les performances sur l'entraînement et le test :\n",
        "\n",
        "Si on observe un écart significatif entre les performances du modèle sur le jeu d'entraînement et sur le jeu de test, cela peut indiquer un problème de surapprentissage (overfitting).\n",
        "\n",
        "Surapprentissage : Le modèle a \"mémorisé\" les données d'entraînement et n'est pas capable de généraliser sur de nouvelles données. Il est très performant sur les données d'entraînement, mais sa performance chute sur le jeu de test.\n",
        "\n",
        "Ajustements pour le surapprentissage :\n",
        "\n",
        "Plusieurs ajustements peuvent être envisagés pour réduire le surapprentissage et améliorer la capacité de généralisation du modèle :\n",
        "\n",
        "  \n",
        "- Augmentation de données pour diversifier les exemples d'entraînement.\n",
        "- Régularisation pour limiter la complexité du modèle et éviter le surapprentissage.\n",
        "\n",
        "- Simplification de l'architecture du modèle.\n",
        "- Ajustement des hyperparamètres, comme le taux d'apprentissage.\n"
      ],
      "metadata": {
        "id": "ni9V6ExHiNfp"
      },
      "id": "ni9V6ExHiNfp"
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## Étape 7 : Prédictions et Visualisation des Résultats\n",
        "\n",
        "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7"
      },
      "outputs": [],
      "source": [
        "# Faire des prédictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs prédictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "\n",
        "- Augmentation de données : appliquer des transformations aléatoires aux images d'entraînement pour augmenter la diversité des exemples.\n",
        "- Raffinement de l'architecture : ajouter des couches, modifier le nombre de filtres, expérimenter avec des fonctions d'activation, ajouter des couches de régularisation.\n",
        "- Ajustement des hyperparamètres : optimiser le taux d'apprentissage, la taille du batch et le nombre d'époques.\n"
      ],
      "metadata": {
        "id": "KL-ikSqwiZjo"
      },
      "id": "KL-ikSqwiZjo"
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## Étape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
        "- Chargé et prétraité le jeu de données CIFAR-10\n",
        "- Exploré et visualisé les données\n",
        "- Construit, compilé et entraîné un modèle CNN\n",
        "- Évalué le modèle et visualisé ses prédictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}