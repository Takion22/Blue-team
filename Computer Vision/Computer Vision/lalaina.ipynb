{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8E7De68YVps",
      "metadata": {
        "id": "a8E7De68YVps"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
        "\n",
        "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K6EHkj63XsUy",
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "source": [
        "# Détails de l'étudiant\n",
        "### Nom(s)  : RANDRIAMANALINA\n",
        "### Prénom(s) : Lalaina Jimmy\n",
        "### Classe : IMTICIA 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## Étape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HqKKXDdRexIA",
      "metadata": {
        "id": "HqKKXDdRexIA"
      },
      "source": [
        "### Reponse 1 :\n",
        "\n",
        "Il essentiel de vérifier la configuration de l'environnement avant de développer un modèle de deep learning parce que la vérification de l'environnement de développement en deep learning est une étape fondamentale pour assurer la fiabilité des résultats. Elle garantit d'abord la stabilité des expériences en évitant les variations de comportement liées aux versions des librairies (comme TensorFlow/Keras), qui pourraient affecter les performances des modèles ou le fonctionnement des couches neuronales. Elle permet ensuite la reproductibilité scientifique en documentant précisément les configurations, facilitant ainsi la réplication des expériences, le débogage et les comparaisons entre approches. Enfin, dans un contexte industriel, cette pratique favorise la collaboration entre équipes hétérogènes et assure un déploiement fiable en production."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## Étape 2 : Chargement et Prétraitement des Données\n",
        "\n",
        "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K0xMfGyXgWjV",
      "metadata": {
        "id": "K0xMfGyXgWjV"
      },
      "source": [
        "### Reponse 2 :\n",
        "\n",
        "\n",
        "La normalisation des pixels et le one-hot encoding sont des étapes fondamentales de prétraitement pour l'entraînement efficace des modèles de vision par ordinateur. La normalisation des pixels stabilise les calculs en évitant que les pixels extrêmes ne dominent les gradients, tout en accélérant la convergence de l'optimiseur grâce à une échelle homogène. Le one-hot encoding, quant à lui, transforme les étiquettes catégorielles en vecteurs binaires, supprimant toute ambiguïté d'ordre entre les classes et permettant une compatibilité optimale avec les fonctions de perte comme la cross-entropy. Ensemble, ces techniques préparent les données à être traitées efficacement par les opérations matricielles des réseaux de neurones, tout en préservant leur signification intrinsèque, ce qui en fait une étape incontournable avant tout apprentissage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## Étape 3 : Exploration et Visualisation des Données\n",
        "\n",
        "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de données d'entraînement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jIdmwz0Ygpqb",
      "metadata": {
        "id": "jIdmwz0Ygpqb"
      },
      "source": [
        "### Reponse 3 :\n",
        "\n",
        "Une distribution déséquilibrée des classes ou des images de faible qualité peut sérieusement compromettre la performance d'un modèle de classification. Dans le premier cas, le modèle développe un biais en faveur des classes majoritaires, négligeant les catégories sous-représentées et réduisant sa capacité à généraliser. Pour y répondre, des méthodes comme l'échantillonnage adaptatif (SMOTE) ou l'ajustement des poids de perte pendant l'entraînement permettent de rééquilibrer l'influence des classes. Concernant les images dégradées, celles-ci introduisent du bruit dans l'apprentissage, conduisant à des caractéristiques non pertinentes. Une solution combinée de filtrage manuel des artefacts, d'augmentation ciblée (recadrage intelligent, correction de la luminosité) et l'utilisation de couches de prétraitement intégrées (comme la normalisation par lots) améliorent la robustesse. Ces approches, couplées à une validation croisée stratifiée, préservent l'intégrité du processus d'apprentissage tout en maximisant l'utilisation des données disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## Étape 4 : Construction du Modèle CNN\n",
        "\n",
        "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le modèle CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbDXrWV-hvpv",
      "metadata": {
        "id": "dbDXrWV-hvpv"
      },
      "source": [
        "Un réseau de neurones convolutif (CNN) est conçu pour analyser des images et en extraire des informations pertinentes pour la classification. Pour cela, il utilise une combinaison de couches spécifiques : convolution, pooling et dropout.\n",
        "\n",
        "1. Les couches de convolution : détecteurs de motifs\n",
        "\n",
        "Imaginez un détective qui examine une scène de crime à la recherche d'indices. Il utilise une loupe pour se concentrer sur des zones spécifiques et identifier des détails importants. Les couches de convolution fonctionnent de manière similaire : elles appliquent des filtres (les \"loupes\") sur l'image pour détecter des motifs locaux, comme des contours, des textures ou des formes simples. Chaque filtre produit une carte de caractéristiques qui met en évidence les zones de l'image où le motif correspondant est présent.\n",
        "\n",
        "2. Les couches de pooling : simplification et robustesse\n",
        "\n",
        "Une fois que le détective a identifié les indices importants, il doit les synthétiser pour avoir une vue d'ensemble de la situation. Les couches de pooling jouent ce rôle : elles réduisent la dimensionnalité des cartes de caractéristiques, en conservant les informations les plus importantes et en éliminant les détails superflus. Cela permet de simplifier le traitement de l'information et de rendre le modèle plus robuste aux petites variations dans les images, comme des légers déplacements ou des rotations.\n",
        "\n",
        "3. Le dropout : éviter les conclusions hâtives\n",
        "\n",
        "Pour éviter de tirer des conclusions trop hâtives à partir d'un seul indice, le détective doit prendre en compte tous les éléments de l'enquête. Le dropout permet d'introduire cette prudence dans le modèle : pendant l'entraînement, il désactive aléatoirement un certain pourcentage de neurones. Cela force le modèle à apprendre des représentations plus robustes et moins dépendantes de neurones individuels, ce qui évite le surapprentissage et améliore la capacité de généralisation.\n",
        "\n",
        "L'interaction des composants : une enquête collaborative\n",
        "\n",
        "Ces trois types de couches interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images et de les classifier avec précision :\n",
        "\n",
        "  Les couches de convolution détectent des motifs locaux dans l'image, comme des contours ou des textures.\n",
        "    Les couches de pooling réduisent la dimensionnalité des cartes de caractéristiques, simplifiant l'information et augmentant la robustesse du modèle.\n",
        "    Le dropout prévient le surapprentissage en forçant le modèle à apprendre des représentations plus robustes.\n",
        "\n",
        "Ensemble, ces couches permettent au modèle d'apprendre une hiérarchie de caractéristiques, des motifs simples aux motifs plus complexes, pour finalement aboutir à une classification précise des images. C'est comme une enquête collaborative où chaque composant apporte sa contribution pour résoudre le mystère de la classification d'images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## Étape 5 : Compilation et Entraînement du Modèle\n",
        "\n",
        "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0l8ETEHch9Tm",
      "metadata": {
        "id": "0l8ETEHch9Tm"
      },
      "source": [
        "### Reponse 5 :\n",
        "\n",
        "Les hyperparamètres comme le taux d'apprentissage et la taille du batch influencent profondément l'entraînement des réseaux de neurones. Un taux trop élevé provoque une divergence des poids (la perte augmente au lieu de diminuer), tandis qu'un taux trop faible ralentit inutilement la convergence. De même, un batch trop petit génère des mises à jour bruyantes, alors qu'un batch trop grand réduit la capacité d'exploration de l'optimiseur. L'optimiseur lui-même, s'il est mal configuré, peut manquer des minima globaux ou osciller autour de solutions sous-optimales. Par exemple, Adam avec un taux mal calibré convergera rapidement vers un plateau médiocre. Ces réglages délicats exigent une compréhension fine des mécanismes d'optimisation : ils déterminent non seulement la vitesse d'apprentissage, mais aussi la qualité finale du modèle et sa capacité à généraliser sur des données inédites."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## Étape 6 : Évaluation du Modèle\n",
        "\n",
        "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
        "\n",
        "### Explication Pratique\n",
        "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Précision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ni9V6ExHiNfp",
      "metadata": {
        "id": "ni9V6ExHiNfp"
      },
      "source": [
        "### Reponse 6 :\n",
        "\n",
        "\n",
        "La perte et la précision sur le jeu de test indiquent respectivement l'erreur globale et le taux de prédictions correctes du modèle face à des données inédites. Un écart marqué entre les performances d'entraînement et de test signale généralement un surapprentissage : le modèle a mémorisé les spécificités du jeu d'entraînement au détriment de sa capacité à généraliser. Pour y remédier, plusieurs stratégies s'offrent au praticien. L'augmentation de données (par rotation, zoom ou ajustement de contraste) enrichit artificiellement la variété des exemples d'apprentissage. La régularisation via des techniques comme le Dropout ou des contraintes de poids (L1/L2) limite la complexité du modèle. Simplifier l'architecture (moins de couches/neurones) peut aussi réduire la surcapacité modélisatrice. L'early stopping interrompt l'entraînement dès que la performance sur le test se dégrade, préservant ainsi la généralisation. Enfin, un réglage minutieux des hyperparamètres (taux d'apprentissage, taille des batches) par validation croisée permet d'optimiser ce compromis flexibilité-robustesse. Ces ajustements concertés visent à aligner la capacité du modèle avec la complexité réelle des données."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## Étape 7 : Prédictions et Visualisation des Résultats\n",
        "\n",
        "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7"
      },
      "outputs": [],
      "source": [
        "# Faire des prédictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs prédictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KL-ikSqwiZjo",
      "metadata": {
        "id": "KL-ikSqwiZjo"
      },
      "source": [
        "### Reponse 7 :\n",
        "\n",
        "\n",
        "L'analyse des prédictions révèle souvent des axes d'amélioration pour renforcer la robustesse du modèle. Une première piste consiste à enrichir le jeu d'entraînement via **l'augmentation de données** (rotations, miroirs, variations de luminosité), forçant le modèle à apprendre des invariants visuels plutôt que des artefacts spécifiques. Parallèlement, **l'optimisation de l'architecture** (ajout de couches convolutives, ajustement des filtres, intégration de mécanismes d'attention) permet de mieux capturer les motifs hiérarchiques complexes. Enfin, **le réglage fin des hyperparamètres** (taux d'apprentissage adaptatif, stratégie de *batch size*, cycles de *learning rate*) affine la dynamique d'entraînement. Ces approches combinées, testées itérativement via des validations croisées, visent à équilibrer précision et généralisation, tout en adaptant le modèle aux spécificités du domaine applicatif."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## Étape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
        "- Chargé et prétraité le jeu de données CIFAR-10\n",
        "- Exploré et visualisé les données\n",
        "- Construit, compilé et entraîné un modèle CNN\n",
        "- Évalué le modèle et visualisé ses prédictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
